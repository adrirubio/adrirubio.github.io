<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Adrian Rubio</title>
    <description>This is my blog where I share my coding journey, my experiences, challenges, and discoveries in the ever-evolving world of programming.</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sun, 13 Jul 2025 13:13:49 +0200</pubDate>
    <lastBuildDate>Sun, 13 Jul 2025 13:13:49 +0200</lastBuildDate>
    <generator>Jekyll v4.3.2</generator><item>
        <title>Retro Snake Game</title>
        <description>&lt;p class=&quot;intro&quot;&gt;&lt;span class=&quot;dropcap&quot;&gt;H&lt;/span&gt;ello and welcome! This week, there was a change of plans. Instead of starting with the Arduino kit, I decided to complete one more project for Shipwrecked: a Retro Snake Game.&lt;/p&gt;

&lt;p&gt;The change of plans happened because the flight cost ‚Ç¨500 per person, and since my dad, my brother, and I were all going, the total would have been around ‚Ç¨1,500, which is quite a lot. So, I decided to do one last project before diving into the Arduino: a Retro Snake Game!&lt;/p&gt;

&lt;p&gt;Before I get into the details of my Snake Game, you might be wondering: why was my brother also coming to Boston? Was he also working on Shipwrecked? Well, no, he was working toward something similar called Neighborhood, where, if you complete a working app in 100 Hackatime hours, you earn a chance to go to San Francisco for as long as you want. You get to stay in houses with people your age. Neighborhood was designed for 16, 17, and 18 year-olds. The only catch? You had to code at least 40 hours a week to stay in SF.&lt;/p&gt;

&lt;p&gt;The plan was for him to go from Boston to Neighborhood. The only problem? Well, Neighborhood was cancelled because too many teenagers met the requirements, and there weren‚Äôt enough houses to accommodate them all. In the end, the situation wasn‚Äôt ideal for the participants, and the best course of action was to cancel the program.&lt;/p&gt;

&lt;p&gt;Since my brother already had a flight booked to Boston, he‚Äôs now looking for alternatives, possibly trying to go for Shipwrecked instead. He had completed 45 out of the 100 required Hackatime hours for Neighborhood, but with the program canceled, he doesn‚Äôt have much motivation.&lt;/p&gt;

&lt;p&gt;I decided to do one more project because, for every hour you complete beyond the required 60 hours across four projects, you earn ‚Ç¨10 toward your flight cost. To get those extra hours, I chose to build a Retro Snake Game. I spent the whole week working on it and only finished it yesterday. I logged 13 hours in total, which adds up to ‚Ç¨130, though it still needs to be reviewed and accepted on the Shipwrecked page. Currently I have ‚Ç¨32 from the little bits of hours from the other four projects. If I get my retro snake game accepted it would total to ‚Ç¨162.&lt;/p&gt;

&lt;p&gt;Retro Snake Game Demo:&lt;/p&gt;
&lt;div style=&quot;text-align: center; margin: 2em 0;&quot;&gt;
  &lt;video controls=&quot;&quot; width=&quot;720&quot; style=&quot;max-width: 100%; border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.1);&quot;&gt;
    &lt;source src=&quot;https://github.com/adrirubio/ai-pdf-reader-demo/raw/main/retro-snake-game-demo.mp4&quot; type=&quot;video/webm&quot; /&gt;
    Your browser does not support the video tag.
  &lt;/video&gt;
&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/adrirubio/retro-snake-game/&quot;&gt;retro-snake-game github&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://pypi.org/project/retro-snake-game/&quot;&gt;retro-snake-game-pypi&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Over the next few weeks before Shipwrecked, I plan to focus on the Arduino kit. I‚Äôm also hoping to earn a bit more toward our flights, since Hackatime is compatible with KiCad, which means I can track hours spent on electronics projects for Shipwrecked. As I mentioned last week, I‚Äôve got some great ideas that I can‚Äôt wait to get into.&lt;/p&gt;
</description><description>&lt;p class=&quot;intro&quot;&gt;&lt;span class=&quot;dropcap&quot;&gt;H&lt;/span&gt;ello and welcome! This week, there was a change of plans. Instead of starting with the Arduino kit, I decided to complete one more project for Shipwrecked: a Retro Snake Game.&lt;/p&gt;
</description><pubDate>Sat, 12 Jul 2025 00:00:00 +0200</pubDate>
        <link>http://localhost:4000/blog/retro-snake-game/</link>
        <guid isPermaLink="true">http://localhost:4000/blog/retro-snake-game/</guid></item><item>
        <title>Shipwrecked Invitation</title>
        <description>&lt;p class=&quot;intro&quot;&gt;&lt;span class=&quot;dropcap&quot;&gt;H&lt;/span&gt;ello and welcome! The past two weeks have been a rollercoaster, but I‚Äôm proud to say that I‚Äôve successfully completed 30 hours of work and built two full projects. All of my projects have been accepted, and I‚Äôm officially invited to Hack Club Shipwrecked!&lt;/p&gt;

&lt;p&gt;On Monday and Tuesday, I completed the QR-Gen project that I had previously started, and I‚Äôm quite proud of how it turned out. I also created a demo video of the finished product and updated the README with the full installation instructions and the demo.
Once the project was complete I put the project up for review.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/adrirubio/qr-gen&quot;&gt;QR-Gen&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;One thing that kept me motivated during those long coding days was watching the leaderboard and seeing myself gradually climb up the ranks.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/shipwrecked/leaderboard.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;QR-Gen Demo:&lt;/p&gt;
&lt;div style=&quot;text-align: center; margin: 2em 0;&quot;&gt;
  &lt;video controls=&quot;&quot; width=&quot;720&quot; style=&quot;max-width: 100%; border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.1);&quot;&gt;
    &lt;source src=&quot;https://github.com/adrirubio/ai-pdf-reader-demo/raw/main/qr-gen-demo.mp4&quot; type=&quot;video/webm&quot; /&gt;
    Your browser does not support the video tag.
  &lt;/video&gt;
&lt;/div&gt;

&lt;p&gt;Next, I began working on my final project, Text-Lens. The goal of Text-Lens is to analyze any given text and present a variety of insights through visual tools like diagrams, graphs, and advanced statistics. It breaks down the text‚Äôs structure and key characteristics to help users better understand and interpret written content. The destop app includes four core metrics: top words, sentence length analysis, punctuation breakdown, sentiment analysis, and some advaced stats.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/adrirubio/text-lens&quot;&gt;Text-Lens&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;As the deadline approached, I realized I was still a few hours short, and doubt started to appear in my mind. But I pushed through those final hours and ultimately submitted my final project just in time.&lt;/p&gt;

&lt;p&gt;Text-Lens Demo:&lt;/p&gt;
&lt;div style=&quot;text-align: center; margin: 2em 0;&quot;&gt;
  &lt;video controls=&quot;&quot; width=&quot;720&quot; style=&quot;max-width: 100%; border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.1);&quot;&gt;
    &lt;source src=&quot;https://github.com/adrirubio/ai-pdf-reader-demo/raw/main/text-lens-demo.mp4&quot; type=&quot;video/webm&quot; /&gt;
    Your browser does not support the video tag.
  &lt;/video&gt;
&lt;/div&gt;

&lt;p&gt;During the next week I read the &lt;a href=&quot;https://ai-2027.com/&quot;&gt;AI 2027&lt;/a&gt; site and a few of the AI papers from my &lt;a href=&quot;https://github.com/adrirubio/ai-learning/blob/main/reading-list.org&quot;&gt;ai-learning&lt;/a&gt; list while I waited for the projects to get accepted. I found the AI 2027 site incredibly interesting as it offers a look into a possible future. I highly recommend reading it for both its insights and perspective.&lt;/p&gt;

&lt;p&gt;On Wednesday, Architext-AI and QR-Gen were accepted. At that point, I was just one project away from being invited to Shipwrecked.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/shipwrecked/two-projects-accepted.png&quot; alt=&quot;&quot; /&gt;&lt;br /&gt;
&lt;img src=&quot;/assets/img/shipwrecked/three-projects-accepted.png&quot; alt=&quot;&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Unfortunately, my final project was initially rejected because it wasn‚Äôt deployed using UV. So on Friday morning, I deployed the project on &lt;a href=&quot;https://pypi.org/project/text-lens/&quot;&gt;PyPI&lt;/a&gt;. Now, you can install it using either ‚Äòpip install text-lens‚Äô or ‚Äòuv pip install text-lens‚Äô, and run it with the command ‚Äòtext-lens‚Äô.&lt;/p&gt;

&lt;p&gt;Not long after, the project was accepted, and the following morning, I was officially invited to Shipwrecked!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/shipwrecked/invited.png&quot; alt=&quot;&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Now, my parents and I will start preparing everything for Shipwrecked (flights, accomodation, etc.). Over the next few weeks, I plan to dive into Arduino to learn more about digital electronics and breadboarding. I already have a few exciting project ideas in mind, and I‚Äôm really looking forward to start work on them!&lt;/p&gt;
</description><description>&lt;p class=&quot;intro&quot;&gt;&lt;span class=&quot;dropcap&quot;&gt;H&lt;/span&gt;ello and welcome! The past two weeks have been a rollercoaster, but I‚Äôm proud to say that I‚Äôve successfully completed 30 hours of work and built two full projects. All of my projects have been accepted, and I‚Äôm officially invited to Hack Club Shipwrecked!&lt;/p&gt;
</description><pubDate>Sat, 05 Jul 2025 00:00:00 +0200</pubDate>
        <link>http://localhost:4000/blog/shipwrecked-invitation/</link>
        <guid isPermaLink="true">http://localhost:4000/blog/shipwrecked-invitation/</guid></item><item>
        <title>Finishing Architext-AI and starting QR-Gen</title>
        <description>&lt;p class=&quot;intro&quot;&gt;&lt;span class=&quot;dropcap&quot;&gt;H&lt;/span&gt;ello and welcome! In this post, I&apos;ll take talk about the latest two weeks of my Shipwrecked adventure. From striving to hit 150 stars to receiving a message that changes it all!&lt;/p&gt;

&lt;p&gt;I left it off two weeks ago after just creating the Architext-AI project. I am proud to say that it is now complete, and I am quite pleased with the final result. The experience reminded me of some fun projects I built as a kid using Tkinter. It was quite nice for a young child to see an interesting UI with widgets and entry boxes, knowing he built them!&lt;/p&gt;

&lt;p&gt;After finalizing the UI for the project, with some assistance from Claude and ChatGPT, I developed a Python script that sets the F5 key as the default key bind to automatically open the Architext-AI desktop app. You can find everything on my GitHub if you‚Äôd like to give it a try. I recorded my screen and created a short demo video, which I later converted into a GIF and uploaded to my GitHub. With that, I completed the 15-hour requirement for the second Shipwrecked project.&lt;/p&gt;

&lt;p&gt;As I mentioned last week, Architext-AI is a straightforward message enhancer featuring a message input box and a prompt that serves as a guideline for the AI. I developed this small project because I need to complete four projects, each having at least 15 hours, with one achieving viral status to qualify for the Shipwrecked hackathon. During this time, my dad and I were actively posting on social media to see if the AI-PDF-Reader project (originally intended to go viral) could gain some traction. I am quite proud to report that, as of July 22, the AI-PDF-Reader has got 49 stars. It‚Äôs still 101 stars short of the 150 needed to attend Shipwrecked, along with the completion of the other three projects of at least 15 hours. However, all of this seems less significant now because two days ago, I read a message that changed everything.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/adrirubio/ai-pdf-reader&quot;&gt;AI-PDF-Reader&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://github.com/adrirubio/architext-ai&quot;&gt;Architext-AI&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Architext-AI Demo:&lt;/p&gt;
&lt;div style=&quot;text-align: center; margin: 2em 0;&quot;&gt;
  &lt;video controls=&quot;&quot; width=&quot;720&quot; style=&quot;max-width: 100%; border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.1);&quot;&gt;
    &lt;source src=&quot;https://github.com/adrirubio/ai-pdf-reader-demo/raw/main/architext-ai-demo.mp4&quot; type=&quot;video/webm&quot; /&gt;
    Your browser does not support the video tag.
  &lt;/video&gt;
&lt;/div&gt;

&lt;p&gt;The message read the following:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;@channel this is biggest announcement EVER:
Finish your Shipwrecked project next week, earn a guaranteed invite (no need to go viral)!
If you complete your 4 projects with at least 15 hours each before next Sunday (June 29), we will waive the virality requirement for you and you‚Äôll earn an invite to Shipwrecked!
You have until Sunday night to ship all your projects in The Bay to have your virality requirement waived!
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This was instantly a game-changer. If the virality requirement were waived, it would save me a lot of effort‚Äîor would it? Achieving 30 hours in just over a week, when I read the message, would be no easy task. At the time, I had just finished the second project (Architext-AI) and was only halfway through. But, as with most things, I decided to give it a try. For the past two days, I have done practically nothing else but focus on accumulating as many hours as possible.&lt;/p&gt;

&lt;p&gt;Now is probably a good time to mention the third project I‚Äôve been working on for the past two days: the QR-Gen. This is a simple Tkinter project where you input text or a link, and it generates the corresponding QR code. I‚Äôve also added a database feature to store past QR codes, and I think it‚Äôs looking nice. So far, I‚Äôve accumulated 9 hours and 48 minutes of work, which isn‚Äôt bad for two days.&lt;/p&gt;

&lt;p&gt;I have 20 hours of work to complete in the next six days to secure a guaranteed invitation to Shipwrecked, and I intend on making every hour count!&lt;/p&gt;

&lt;p&gt;I‚Äôm looking forward to sharing my journey and the final results of the QR-Gen project next week, along with my next project!&lt;/p&gt;

&lt;p&gt;This post documents the state of the QR-Gen as of July 22, 2025&lt;br /&gt;
To see the current state of the model visit:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/adrirubio/qr-gen&quot;&gt;qr-gen github&lt;/a&gt;&lt;/p&gt;
</description><description>&lt;p class=&quot;intro&quot;&gt;&lt;span class=&quot;dropcap&quot;&gt;H&lt;/span&gt;ello and welcome! In this post, I&apos;ll take talk about the latest two weeks of my Shipwrecked adventure. From striving to hit 150 stars to receiving a message that changes it all!&lt;/p&gt;
</description><pubDate>Sun, 22 Jun 2025 00:00:00 +0200</pubDate>
        <link>http://localhost:4000/blog/finishing-Architext-AI-and-starting-QR-Gen/</link>
        <guid isPermaLink="true">http://localhost:4000/blog/finishing-Architext-AI-and-starting-QR-Gen/</guid></item><item>
        <title>Starting Architext-AI</title>
        <description>&lt;p class=&quot;intro&quot;&gt;&lt;span class=&quot;dropcap&quot;&gt;H&lt;/span&gt;ello and welcome! In this post, I wrapped up the AI PDF Reader by releasing a Windows version and started my next project ‚Äî an AI writing assistant called Architext-AI.&lt;/p&gt;

&lt;p&gt;I started the week by creating a demo video for the AI PDF Reader, which is now embedded in  &lt;a href=&quot;https://adrianrubio.org/blog/my-ai-pdf-reader-how-and-why-I-build-it/&quot;&gt;last week‚Äôs blog post.&lt;/a&gt; I‚Äôm really happy with how the final version turned out. To wrap up the project, I released a Windows version and improved the README.
Hopefully, the AI PDF Reader can gain some traction, as my dad and I will be sharing it across various social media platforms. Our goal is to reach 150 stars on GitHub.&lt;/p&gt;

&lt;p&gt;Next, I began brainstorming ideas for my next project. With some help from my dad, we came up with a simple Python program: using a predefined command, you can open a small window where write your message, and the AI will enhance it for you‚Äîimproving clarity and overall quality. I think it would be something everyone would use.&lt;/p&gt;

&lt;p&gt;Yesterday, I got started on the project. I planned out the structure and chose &lt;a href=&quot;https://docs.python.org/3/library/tkinter.html&quot;&gt;Tkinter&lt;/a&gt; for the GUI and the &lt;a href=&quot;https://openai.github.io/openai-agents-python/&quot;&gt;OpenAI SDK&lt;/a&gt; for the AI capabilites. I set up all the necessary files, and now I‚Äôm focusing on building the Python GUI. Hopefully, by next week, I‚Äôll have something that looks good and works smoothly.&lt;/p&gt;

&lt;p&gt;This post documents the state of Architext-AI as of June 8, 2025&lt;br /&gt;
To see the current state of the pdf reader visit:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/adrirubio/architext-ai&quot;&gt;architext-ai github&lt;/a&gt;&lt;/p&gt;
</description><description>&lt;p class=&quot;intro&quot;&gt;&lt;span class=&quot;dropcap&quot;&gt;H&lt;/span&gt;ello and welcome! In this post, I wrapped up the AI PDF Reader by releasing a Windows version and started my next project ‚Äî an AI writing assistant called Architext-AI.&lt;/p&gt;
</description><pubDate>Sun, 08 Jun 2025 00:00:00 +0200</pubDate>
        <link>http://localhost:4000/blog/starting-architext-ai/</link>
        <guid isPermaLink="true">http://localhost:4000/blog/starting-architext-ai/</guid></item><item>
        <title>My AI PDF Reader: The Story of How (and Why) I Built It</title>
        <description>&lt;p class=&quot;intro&quot;&gt;&lt;span class=&quot;dropcap&quot;&gt;H&lt;/span&gt;ello and welcome! In this post I&apos;m going to tell you the whole story of my AI PDF reader ‚Äì like, how I built it and the reasons why. This project was a pretty wild ride with some tough challenges and fun wins, and seeing it finally work just how I wanted is awesome!&lt;/p&gt;

&lt;p&gt;I‚Äôm a huge &lt;a href=&quot;https://karpathy.ai/&quot;&gt;Andrej Karpathy&lt;/a&gt; fan (the guy who invented the term &lt;em&gt;vibe coding&lt;/em&gt;) and pretty much watch all his videos. One time, while I was watching his ‚ÄúHow I use LLMs‚Äù video, he said that he wished there was a tool to make reading PDFs way easier. That just clicked for me! I read a lot of AI papers (about how different AI systems are built), and I often get stuck on tricky parts. The idea of highlighting text and getting help right away to understand it? That sounded awesome!&lt;/p&gt;

&lt;p&gt;He specifically imagined a tool where you could highlight text in the PDF and get AI explanations. He actually talks about the idea &lt;a href=&quot;https://www.youtube.com/watch?v=EWvNQjAaOHw&amp;amp;t=3507s&quot;&gt;right here!&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;So, I decided to give it a shot!&lt;/p&gt;

&lt;p&gt;This was my very first desktop app using &lt;em&gt;Electron&lt;/em&gt;, so for some of the harder parts, I &lt;strong&gt;vibe coded&lt;/strong&gt; it ‚Äì you know, working with an AI (Claude 3.7 via &lt;a href=&quot;https://www.cursor.com/&quot;&gt;Cursor&lt;/a&gt;) helping me along. I definitely used this chance to understand these frameworks better, and now they don‚Äôt seem as confusing as before! I also learned that &lt;em&gt;vibe coding&lt;/em&gt; isn‚Äôt as easy as it looks. You have to explain everything super clearly to the AI, and sometimes it would just get stuck, meaning I‚Äôd have to dive in and figure things out. Getting the UI to work was awesome! But sometimes trying to fix one tiny bug would just make a bunch of new ones pop up ‚Äì so frustrating! Still, I learned a ton about &lt;em&gt;Electron,&lt;/em&gt; &lt;em&gt;npm&lt;/em&gt; and &lt;em&gt;JavaScript&lt;/em&gt;. I even got used to using Git branches, which was super helpful for trying new stuff without breaking everything. And when I had a stable version, I learned how to make GitHub Releases so people could actually download and use the app! Looking back it was a really great experience and I learned so much!&lt;/p&gt;

&lt;div style=&quot;text-align: center; margin: 2em 0;&quot;&gt;
  &lt;video controls=&quot;&quot; width=&quot;720&quot; style=&quot;max-width: 100%; border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.1);&quot;&gt;
    &lt;source src=&quot;https://github.com/adrirubio/ai-pdf-reader-demo/raw/main/ai-pdf-reader-demo.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    Your browser does not support the video tag.
  &lt;/video&gt;
&lt;/div&gt;

&lt;p&gt;I really hope this can be a useful tool for students, researchers, or anyone who wants to read PDFs more efficiently.
You can find the project, download the app, and see all the code on my GitHub page: &lt;a href=&quot;https://github.com/adrirubio/ai-pdf-reader&quot;&gt;AI PDF reader&lt;/a&gt;&lt;br /&gt;
If you think it‚Äôs cool or useful, starring the project on GitHub would mean the world to me! It helps other people find it and really motivates me to keep building new things. I‚Äôd also love to hear what you think or if you have any ideas!&lt;/p&gt;

&lt;p&gt;Thanks for reading and checking out my project!&lt;/p&gt;
</description><description>&lt;p class=&quot;intro&quot;&gt;&lt;span class=&quot;dropcap&quot;&gt;H&lt;/span&gt;ello and welcome! In this post I&apos;m going to tell you the whole story of my AI PDF reader ‚Äì like, how I built it and the reasons why. This project was a pretty wild ride with some tough challenges and fun wins, and seeing it finally work just how I wanted is awesome!&lt;/p&gt;
</description><pubDate>Sat, 31 May 2025 00:00:00 +0200</pubDate>
        <link>http://localhost:4000/blog/my-ai-pdf-reader-how-and-why-I-build-it/</link>
        <guid isPermaLink="true">http://localhost:4000/blog/my-ai-pdf-reader-how-and-why-I-build-it/</guid></item><item>
        <title>Improving the AI PDF Reader</title>
        <description>&lt;p class=&quot;intro&quot;&gt;&lt;span class=&quot;dropcap&quot;&gt;H&lt;/span&gt;ello and welcome! Over the past two weeks, I‚Äôve been working hard on the AI PDF Reader. I‚Äôve improved the UI, integrated the AI API, and am now implementing a database to support the reader.&lt;/p&gt;

&lt;p&gt;I haven‚Äôt posted in the past two weeks as I‚Äôve been fully focused on developing the AI PDF Reader. Now that I‚Äôve found a moment, here‚Äôs a quick recap of what I‚Äôve been working on and what to expect moving forward.&lt;/p&gt;

&lt;p&gt;I started the week by addressing several UI issues to make the interface cleaner and more user-friendly.
I removed the ‚ÄúSimple,‚Äù ‚ÄúLike I‚Äôm Five,‚Äù and ‚ÄúTechnical‚Äù modes, keeping only the ‚ÄúCustom‚Äù option to streamline the experience. I also enlarged the chat area and slightly repositioned the PDF viewer to the left for better layout balance. Instead of dumping the entire highlighted text into the chat, it now generates a compact link or button that takes you directly to the relevant section in the PDF‚Äîmaking navigation much smoother. Additionally, when starting a new chat, it can now retain full context from the entire PDF.&lt;/p&gt;

&lt;p&gt;After that, I began integrating the API.
The app now supports OpenAI API keys, correctly detects them, and uses them for generating responses.
Here is a quick look at what‚Äôs changed from where we left off to this week:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/shipwrecked/pdf-reader-home.png&quot; alt=&quot;&quot; /&gt;&lt;br /&gt; &lt;img src=&quot;/assets/img/shipwrecked/pdf-reader-home2.png&quot; alt=&quot;&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Also added:
&lt;img src=&quot;/assets/img/shipwrecked/full-context.png&quot; alt=&quot;&quot; /&gt;&lt;br /&gt; &lt;img src=&quot;/assets/img/shipwrecked/chat-with-full-context.png&quot; alt=&quot;&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Yesterday, I joined the Shipwrecked kickoff call and got to see what other teenagers are building. It was exciting to hear from other builders, share early progress, and get inspired by a wide range of creative ideas. Being part of a community like this adds an extra layer of motivation.&lt;/p&gt;

&lt;p&gt;So far, I‚Äôve spent about 14 hours on the project. Once I finish implementing the database and polish things up a bit, I plan to launch a small web demo. After that, I‚Äôll start promoting it across different platforms hopefully reaching 150 stars on GitHub.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/shipwrecked/23.png&quot; alt=&quot;&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;This post documents the state of the AI pdf reader as of May 18, 2025&lt;br /&gt;
To see the current state of the pdf reader visit:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/adrirubio/ai-pdf-reader&quot;&gt;AI pdf reader github&lt;/a&gt;&lt;/p&gt;

</description><description>&lt;p class=&quot;intro&quot;&gt;&lt;span class=&quot;dropcap&quot;&gt;H&lt;/span&gt;ello and welcome! Over the past two weeks, I‚Äôve been working hard on the AI PDF Reader. I‚Äôve improved the UI, integrated the AI API, and am now implementing a database to support the reader.&lt;/p&gt;
</description><pubDate>Sun, 18 May 2025 00:00:00 +0200</pubDate>
        <link>http://localhost:4000/blog/improving-the-ai-pdf-reader/</link>
        <guid isPermaLink="true">http://localhost:4000/blog/improving-the-ai-pdf-reader/</guid></item><item>
        <title>Hack Club Shipwrecked</title>
        <description>&lt;p class=&quot;intro&quot;&gt;&lt;span class=&quot;dropcap&quot;&gt;H&lt;/span&gt;ello and welcome! This week, I wrapped up reviewing the SSD object detection model and was just about to dive into the line-following model‚Äîwhen a message in the Hack Club announcements caught my attention.&lt;/p&gt;

&lt;p&gt;I kicked off the week by discussing the SSD model with Claude, breaking down each component to understand how everything fits together. It really helped me get a better grip on some of the more complex concepts. I also generated a few more inference examples‚ÄîI‚Äôm still amazed at how well the model performs! To top it off, the weights are also getting some attention on Hugging Face too: it‚Äôs already been downloaded 90 times this month, and I only published it halfway through.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/ssd/model-weight-downloads.png&quot; alt=&quot;&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;I had just started diving into the line-following model for the ML Rover when a message popped up in the Hack Club announcements channel‚Äîand it definitely stole my attention.&lt;/p&gt;

&lt;p&gt;Introducing‚Ä¶
Shipwrecked üèùÔ∏è ‚Äî a Hack Club hackathon on an island!
From August 8‚Äì11, you ü´µ and 130 other Hack Clubbers will gather on Cathleen Stone Island in Massachusetts Bay for a once-in-a-lifetime, 4-day, story-driven hackathon.
As soon as you arrive, you‚Äôll start working together to survive!&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;To get invited, complete ‚ÄúThe Bay‚Äù:&lt;/li&gt;
  &lt;li&gt;Spend 60 hours building 4 projects (about 15 hours each) that you‚Äôre truly proud of&lt;/li&gt;
  &lt;li&gt;Share them with the world‚Äîmake at least one go viral (Hack Club will help with workshops, online events, and more)&lt;/li&gt;
  &lt;li&gt;Get invited to Shipwrecked! (Travel stipends available)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As soon as I saw the announcement, a change of plans was inevitable‚ÄîI decided to postpone the ML Rover project. I mean, how could I pass up the chance to go to Boston for a once-in-a-lifetime Hack Club hackathon on an island?&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://shipwrecked.hackclub.com/&quot;&gt;Shipwrecked link&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/shipwrecked/shipwrecked.png&quot; alt=&quot;&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;So, naturally, I started thinking about what kind of project could actually go viral. I have to admit‚ÄîI was stuck for a while. Every idea I came up with felt off, and I‚Äôd second-guess it almost immediately. That is, until my brother stepped in with an idea he picked up from one of Karpathy‚Äôs videos. In it, Karpathy mentioned that he didn‚Äôt know of any PDF reader where you could highlight text and chat with an AI about it. And just like that, I knew what I wanted to build.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://shipwrecked.hackclub.com/info/go-viral/&quot;&gt;How to go viral&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;You should know‚ÄîI‚Äôm not an expert in CSS, JavaScript, or front-end development in general, so I‚Äôve been relying heavily on Claude to help guide me through this project. Still, the core idea is simple but powerful: a normal PDF reader, but enhanced with smart AI features. The main one? You can highlight a passage and instantly get a response from an AI chat that pops up right beside it.&lt;/p&gt;

&lt;p&gt;I started working on it just two days ago, and here‚Äôs where it currently stands:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/shipwrecked/open-pdf-landing-page.png&quot; alt=&quot;&quot; /&gt;&lt;br /&gt;
&lt;img src=&quot;/assets/img/shipwrecked/pdf-reader-home.png&quot; alt=&quot;&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Right now, the project has a simple landing page where you can upload and open a PDF. Once the PDF is loaded, you can highlight any text, and a small bubble with a chat icon appears next to your selection. When you click the icon, a chat window opens, showing the highlighted message and giving you the option to choose how you‚Äôd like the AI to respond: Simple, Like I‚Äôm 5, Technical, or Custom. You can open multiple chats, close them, and ask the AI anything within each one.&lt;/p&gt;

&lt;p&gt;I haven‚Äôt integrated the actual AI yet‚Äîbut that‚Äôs coming next week!&lt;/p&gt;

&lt;p&gt;Next week, I‚Äôm planning to integrate the AI into the chat feature, fix a few small bugs, and maybe even start exploring some of the other AI features I‚Äôve got in mind. It‚Äôs still early, but I‚Äôm excited about where this is heading!&lt;/p&gt;

&lt;p&gt;This post documents the state of the AI pdf reader as of April 27, 2025&lt;br /&gt;
To see the current state of the pdf reader visit:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/adrirubio/ai-pdf-reader&quot;&gt;AI pdf reader github&lt;/a&gt;&lt;/p&gt;
</description><description>&lt;p class=&quot;intro&quot;&gt;&lt;span class=&quot;dropcap&quot;&gt;H&lt;/span&gt;ello and welcome! This week, I wrapped up reviewing the SSD object detection model and was just about to dive into the line-following model‚Äîwhen a message in the Hack Club announcements caught my attention.&lt;/p&gt;
</description><pubDate>Sun, 27 Apr 2025 00:00:00 +0200</pubDate>
        <link>http://localhost:4000/blog/hack-club-shipwrecked/</link>
        <guid isPermaLink="true">http://localhost:4000/blog/hack-club-shipwrecked/</guid></item><item>
        <title>Inference Using SSD Weights</title>
        <description>&lt;p class=&quot;intro&quot;&gt;&lt;span class=&quot;dropcap&quot;&gt;H&lt;/span&gt;ello and welcome! This week, I took a deeper dive into last week&apos;s model, did some additional training, and let me just say‚Äîthe inference code made predictions, and they‚Äôre genuinely impressive!&lt;/p&gt;

&lt;p&gt;I kicked off the week by listening to a few podcasts created with Notebook LM, which helped set the stage for deeper understanding. I also spent some time revising the code alongside Claude, going through the model architecture and key components more thoroughly. That combination really clicked for me‚ÄîI came away feeling like I finally had a much clearer grasp of how the model works.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/adrirubio/ml-rover/blob/93cbd2abda91a5a34217186b75c0cade86c84099/ssd/ssd-object-detection.py&quot;&gt;SSD model at this phase&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Once I felt confident in how the model worked‚Äîaround Wednesday‚ÄîI decided it was time to train it. Unfortunately, the initial results were pretty disappointing. Every time I kicked off training, the first few epochs showed a really high loss, which wasn‚Äôt too surprising at first. But what really threw me off was that the mAP@0.50 stayed stuck at 0.0000 for the first 10 epochs. Even after that, the improvements were minimal‚Äîbarely creeping up with tiny values that were barely meaningful.&lt;/p&gt;

&lt;p&gt;After that, I started tweaking some of the weights, hoping to find a sweet spot that would finally unlock the model‚Äôs potential. But no matter what I tried, nothing seemed to make a meaningful difference. It was especially frustrating because, on paper, this model had a pretty advanced architecture. It used an EfficientNet‚ÄëB1 backbone with an FPN, incorporated sophisticated augmentations through Albumentations, supported mixed‚Äëprecision training, and featured a three‚Äëphase learning-rate scheduler. On top of that, the loss function was optimized with GIoU for bounding boxes and Focal Loss for classification‚Äîso expectations were high.&lt;/p&gt;

&lt;p&gt;But despite all that, after full training, the model only managed to hit around 40 mAP@0.50‚Äîwhich is disappointingly low for a setup this advanced.&lt;/p&gt;

&lt;p&gt;By this point, I was honestly exhausted. It was Friday, and I‚Äôd spent the better part of the week going back and forth, tweaking weights and adjusting parameters, hoping for a breakthrough. But the model just kept underperforming, no matter what I threw at it. So‚Äînaturally‚ÄîI started thinking about giving up.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/ssd/SSD-0-mAP.png&quot; alt=&quot;&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;But‚ÄîI had one last shot left in me.&lt;/p&gt;

&lt;p&gt;So, I turned to Claude for some insight. Naturally, I was curious‚Äîhow could a model with such an advanced architecture perform so poorly? I started digging into the original SSD paper, specifically looking at how their model managed to reach 72 mAP@0.5. That‚Äôs when it hit me: I had likely overcomplicated my implementation. By layering on too many advanced techniques all at once, I may have introduced more confusion than clarity to the model. Instead of boosting performance, all those additions seemed to interfere with learning.&lt;/p&gt;

&lt;p&gt;I decided to simplify the model, keeping the SSD paper as my main reference. Following its approach step by step, I started stripping away some of the complexity and sticking to the core elements of their design. In the end, the model I ended up with was quite similar to the SSD300 from the paper.&lt;/p&gt;

&lt;p&gt;So, I started training the simplified model. I think the following snippets really say it all.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/ssd/SSD-training-snippet.png&quot; alt=&quot;&quot; /&gt;&lt;br /&gt;
&lt;img src=&quot;/assets/img/ssd/SSD-training-snippet2.png&quot; alt=&quot;&quot; /&gt;&lt;br /&gt;
&lt;img src=&quot;/assets/img/ssd/SSD-training-snippet3.png&quot; alt=&quot;&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;The model finished with an mAP@0.5 of 0.76 (76%), which is very close to the 77% reported in the paper. This marked a huge improvement compared to the 40% mAP of the previous model. But now came the moment of truth: I had to test it out. So, I asked Claude to create two simple sets of inference code‚Äîone that randomly selects an image from the Pascal VOC dataset and predicts the bounding boxes and labels, and another where you provide the image manually.&lt;/p&gt;

&lt;p&gt;The model did not disappoint.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/ssd/1_pred.png&quot; alt=&quot;&quot; /&gt;&lt;br /&gt;
&lt;img src=&quot;/assets/img/ssd/2_pred.png&quot; alt=&quot;&quot; /&gt;&lt;br /&gt;
&lt;img src=&quot;/assets/img/ssd/3_pred.png&quot; alt=&quot;&quot; /&gt;&lt;br /&gt;
&lt;img src=&quot;/assets/img/ssd/4_pred.png&quot; alt=&quot;&quot; /&gt;&lt;br /&gt;
&lt;img src=&quot;/assets/img/ssd/5_pred.png&quot; alt=&quot;&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;You can also check out the final trained model weights, now available on Hugging Face. For more examples and the full inference code, head over to the GitHub repo. Feel free to test it, fork it, or build on it!&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://huggingface.co/pro-grammer/SSD&quot;&gt;SSD weights&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://github.com/adrirubio/ml-rover/tree/main/ssd&quot;&gt;SSD github&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Next week, I plan to further deepen my understanding by reviewing the newer SSD models and beginning work on the next model for the ML-Rover project. Once that‚Äôs complete, I‚Äôll start integrating the models into the Adeept PiCar-B.&lt;/p&gt;

&lt;p&gt;This post documents the state of the SSD model as of April 20, 2025&lt;br /&gt;
To see the current state of the model visit:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/adrirubio/ml-rover/blob/main/ssd/ssd-object-detection.py&quot;&gt;SSD object detection model&lt;/a&gt;&lt;/p&gt;
</description><description>&lt;p class=&quot;intro&quot;&gt;&lt;span class=&quot;dropcap&quot;&gt;H&lt;/span&gt;ello and welcome! This week, I took a deeper dive into last week&apos;s model, did some additional training, and let me just say‚Äîthe inference code made predictions, and they‚Äôre genuinely impressive!&lt;/p&gt;
</description><pubDate>Sun, 20 Apr 2025 00:00:00 +0200</pubDate>
        <link>http://localhost:4000/blog/inference-using-SSD/</link>
        <guid isPermaLink="true">http://localhost:4000/blog/inference-using-SSD/</guid></item><item>
        <title>Finalizing SSD Model and Training</title>
        <description>&lt;p class=&quot;intro&quot;&gt;&lt;span class=&quot;dropcap&quot;&gt;H&lt;/span&gt;ello and welcome! This week, I focused on deepening my understanding of last week‚Äôs model by creating inference code and making further improvements. The final results are looking even more promising than before!&lt;/p&gt;

&lt;p&gt;During this week, I spent most of my time reviewing the code and making sure I fully understood some of the harder concepts. Since I‚Äôm not creating the model completely from scratch ‚Äî I use Claude to help take it to the next level ‚Äî some parts of the code can be harder to grasp (for example, the loss function definition).
To stay organized, I followed some Org mode notes I made a while back:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Tips to improve coding
- Start by learning concepts for new model using coding journal
- Use claude effectively when learning new concepts:
    - Make small modifications to code generated by claude
    - Ask for lots of explanations of concepts
    - Request code outlines to fill in 
    - Ask &quot;why&quot; questions about how the generated code works
- Challenge to write small functions I know how to write:
    - Have claude review the code
- Write in blog weekly to recap week&apos;s work
- Create podcasts for the finished model and listen to further deepen knowledge
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To deepen my knowledge of the model, I created some podcasts using Notebook LM (AI-generated podcasts). I would listen to them in the car, at the library, while studying, and more ‚Äî helping me take my understanding to the next level. By the end of Thursday, I felt that I understood the code much better.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/ssd/SSD-notebook-lm-loading-data.png&quot; alt=&quot;&quot; /&gt;&lt;br /&gt;
&lt;img src=&quot;/assets/img/ssd/SSD-notebook-lm-ssd-architecture.png&quot; alt=&quot;&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Once I understood the code better, I created some simple inference code for the model (with Claude‚Äôs help) to test it out. I didn‚Äôt upload the code to GitHub, but running the tests showed that Claude‚Äôs predictions from last week were a bit off.&lt;/p&gt;

&lt;p&gt;The real model wasn‚Äôt able to detect objects and place bounding boxes with 75‚Äì80% mAP as expected. It recognized something, but the placements were often inaccurate, and the classification results had noticeable defects too.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/adrirubio/ml-rover/tree/dbe25b3a8f17d60ce391c47c27b042cb7aa144e1&quot;&gt;SSD model at this phase&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;So, I knew what I had to do.&lt;/p&gt;

&lt;p&gt;The improved SSD model now uses an EfficientNet-B1 backbone with a Feature Pyramid Network (FPN). The training process combines SGD optimization with momentum (0.9) and a three-phase learning rate schedule. I also applied extensive data augmentation techniques, including mosaic transformations, which merge four training images to help improve small object detection.&lt;/p&gt;

&lt;p&gt;For more precise localization, I implemented Generalized IoU (GIoU) loss for bounding box regression. To boost classification accuracy and better handle class imbalance, I used Focal Loss. According to Claude‚Äôs predictions, the updated model should achieve 80‚Äì84% mAP on the Pascal VOC dataset.&lt;/p&gt;

&lt;p&gt;After making these changes, I created new podcasts with the updated code and plan to start listening to them next week.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/ssd/SSD-notebook-lm-ssd-architecture2.png&quot; alt=&quot;&quot; /&gt;&lt;br /&gt;
&lt;img src=&quot;/assets/img/ssd/SSD-notebook-lm-ssd-loss.png&quot; alt=&quot;&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;This post documents the state of the SSD model as of April 13, 2025&lt;br /&gt;
To see the current state of the model visit:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/adrirubio/ml-rover/blob/main/ssd/ssd-object-detection.py&quot;&gt;SSD object detection model&lt;/a&gt;&lt;/p&gt;
</description><description>&lt;p class=&quot;intro&quot;&gt;&lt;span class=&quot;dropcap&quot;&gt;H&lt;/span&gt;ello and welcome! This week, I focused on deepening my understanding of last week‚Äôs model by creating inference code and making further improvements. The final results are looking even more promising than before!&lt;/p&gt;
</description><pubDate>Sun, 13 Apr 2025 00:00:00 +0200</pubDate>
        <link>http://localhost:4000/blog/finalizing-ssd-model-and-training/</link>
        <guid isPermaLink="true">http://localhost:4000/blog/finalizing-ssd-model-and-training/</guid></item><item>
        <title>Finishing SSD Model and Training</title>
        <description>&lt;p class=&quot;intro&quot;&gt;&lt;span class=&quot;dropcap&quot;&gt;H&lt;/span&gt;ello and welcome! This week, I completed the model and began the debugging process, which involved making numerous changes across the entire system. After that, I kicked off the first full training run, made some adjustments based on the results, and retrained the model. So far, the results are looking very promising!&lt;/p&gt;

&lt;p&gt;During the debugging phase, the model underwent significant changes. I removed the Pascal VOC dataset that was previously loaded from Hugging Face and instead downloaded the original 2007 Pascal VOC dataset directly to the VM (I‚Äôll explain what the VM is and its role later). I also enhanced the data transformations applied to the datasets by adding augmentations like random shadows, Gaussian noise, and Gaussian blur. These improvements aim to boost training performance and model generalization.&lt;/p&gt;

&lt;p&gt;I adjusted the feature map sizes from [38, 19, 10, 5, 3, 1] to [37, 18, 18, 9, 5, 2] to better balance spatial resolution and receptive fields. Additionally, I modified the VGG backbone: it now uses the full VGG16 feature extractor up to layer 23, then continues from layer 30, aligning more closely with the original SSD architecture. I also restructured the convolutional layers to vary the channel sizes ‚Äî using 1024, 512, and 256 ‚Äî instead of keeping them fixed at 256, improving feature representation across scales.&lt;/p&gt;

&lt;p&gt;The loss function remains largely the same, but I introduced checks for empty ground truth boxes and improved the handling of edge cases for increased robustness. The training loop was also enhanced to support early stopping, model checkpointing, and training visualization. Finally, a number of smaller refinements were made throughout the process to get the model fully ready for training.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/adrirubio/ml-rover/tree/6e5d2f788b96d3f1b72b5b5f93db69305c5fc4b1&quot;&gt;SSD model at this phase&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;It‚Äôs a good time to mention that the entire training process would have been impossible without the Nebius VM. I set it up on my computer two months ago, and ever since, I‚Äôve been using it to train my models at just $2.30 an hour. With its H100 GPU, it significantly accelerates training and inference, making it perfect for handling my larger models efficiently.&lt;/p&gt;

&lt;p&gt;And so, I began training.&lt;/p&gt;

&lt;p&gt;The model trained for 35 epochs, finishing with a final loss of 1740.8066 and a best loss of 1648.3888. This translates to an estimated 70‚Äì73% mAP, which is right in line with the original SSD300 paper‚Äôs reported 74% mAP. Training didn‚Äôt take long, and the results were genuinely promising.&lt;/p&gt;

&lt;p&gt;‚Ä¶ &lt;br /&gt;
Completed in 0:00:06.431447 &lt;br /&gt;
Epoch 8/35 &lt;br /&gt;
Batch 20/157 - Loss: 3314.0496 &lt;br /&gt;
Batch 40/157 - Loss: 3511.7007 &lt;br /&gt;
Batch 60/157 - Loss: 3111.1152 &lt;br /&gt;
Batch 80/157 - Loss: 2806.2126 &lt;br /&gt;
Batch 100/157 - Loss: 2849.9556 &lt;br /&gt;
Batch 120/157 - Loss: 3000.4382 &lt;br /&gt;
Batch 140/157 - Loss: 2939.6262 &lt;br /&gt;
Batch 157/157 - Loss: 3830.0691 &lt;br /&gt;
Epoch 8 completed in 0:00:06.913375 &lt;br /&gt;
Train Loss: 3302.9789 &lt;br /&gt;
Val Loss: 3030.0992 &lt;br /&gt;
Saving best model with validation loss: 3030.0992 &lt;br /&gt;
‚Ä¶ &lt;br /&gt;
Epoch 35/35 &lt;br /&gt;
Batch 20/157 - Loss: 1721.4296 &lt;br /&gt;
Batch 40/157 - Loss: 1765.3861 &lt;br /&gt;
Batch 60/157 - Loss: 1596.6831 &lt;br /&gt;
Batch 80/157 - Loss: 1818.6946 &lt;br /&gt;
Batch 100/157 - Loss: 1464.0607 &lt;br /&gt;
Batch 120/157 - Loss: 1789.6305 &lt;br /&gt;
Batch 140/157 - Loss: 2008.2661 &lt;br /&gt;
Batch 157/157 - Loss: 1806.7076 &lt;br /&gt;
Epoch 35 completed in 0:00:07.030001 &lt;br /&gt;
Train Loss: 1740.8066 &lt;br /&gt;
Val Loss: 1648.3888 &lt;br /&gt;
Final model saved to ssd_pascal_voc_final.pth &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/ssd/ssd-loss-plot-old.png&quot; alt=&quot;&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;But I wasn‚Äôt finished. I knew I could do better.&lt;/p&gt;

&lt;p&gt;So, using insights from the previous results, I made a few key changes. I enabled mixed precision training with AMP to speed up computation and reduce memory usage, and I replaced the standard loss function with Focal Loss to better address class imbalance. I also optimized the learning rate strategy by starting with lower initial values and extended the training duration from 35 to 100 epochs, aiming to improve stability and enhance detection accuracy, especially for harder-to-detect objects.&lt;/p&gt;

&lt;p&gt;The results did not disappoint.&lt;/p&gt;

&lt;p&gt;The model completed its training beautifully! It achieved a final validation loss of 1928.09, which is excellent ‚Äî especially considering that with Focal Loss, the raw loss values don‚Äôt directly translate to accuracy. This translates to an estimated mAP of 82‚Äì84% on the Pascal VOC dataset, marking a significant improvement over the initial run.&lt;/p&gt;

&lt;p&gt;Here‚Äôs what Claude had to say about the model:&lt;/p&gt;

&lt;p&gt;‚ÄúYour model has reached a validation loss of 1934.89 at epoch 58, which is even better than I predicted. This loss level puts your SSD model in an excellent position for real-world detection tasks. For context, this level of performance would make your model competitive with many production-ready object detectors.‚Äù&lt;/p&gt;

&lt;p&gt;Epoch 1/100 &lt;br /&gt;
Batch 20/157 - Loss: 12212.2188 &lt;br /&gt;
Batch 40/157 - Loss: 13119.7129 &lt;br /&gt;
Batch 60/157 - Loss: 12890.0430 &lt;br /&gt;
Batch 80/157 - Loss: 12896.1777 &lt;br /&gt;
Batch 100/157 - Loss: 10839.2949 &lt;br /&gt;
Batch 120/157 - Loss: 12710.5645 &lt;br /&gt;
Batch 140/157 - Loss: 11867.0479 &lt;br /&gt;
Batch 157/157 - Loss: 10401.2627 &lt;br /&gt;
Warmup phase: learning rate set to 0.000010 &lt;br /&gt;
Epoch 1 completed in 0:00:07.048314 &lt;br /&gt;
‚Ä¶ &lt;br /&gt;
Epoch 50/100 &lt;br /&gt;
Batch 20/157 - Loss: 2943.6089 &lt;br /&gt;
Batch 40/157 - Loss: 1767.0057 &lt;br /&gt;
Batch 60/157 - Loss: 2459.3105 &lt;br /&gt;
Batch 80/157 - Loss: 2643.3643 &lt;br /&gt;
Batch 100/157 - Loss: 2142.9924 &lt;br /&gt;
Batch 120/157 - Loss: 2283.0781 &lt;br /&gt;
Batch 140/157 - Loss: 2101.7227 &lt;br /&gt;
Batch 157/157 - Loss: 2728.4829 &lt;br /&gt;
Cosine phase: learning rate set to 0.000011 &lt;br /&gt;
Epoch 50 completed in 0:00:06.342008 &lt;br /&gt;
Train Loss: 2154.6789 &lt;br /&gt;
Val Loss: 1995.7843 &lt;br /&gt;
Saving best model with validation loss: 1995.7843 &lt;br /&gt;
‚Ä¶ &lt;br /&gt;
Epoch 100/100 &lt;br /&gt;
Batch 20/157 - Loss: 1751.8605 &lt;br /&gt;
Batch 40/157 - Loss: 2114.5859 &lt;br /&gt;
Batch 60/157 - Loss: 2165.1792 &lt;br /&gt;
Batch 80/157 - Loss: 2106.7981 &lt;br /&gt;
Batch 100/157 - Loss: 2118.8838 &lt;br /&gt;
Batch 120/157 - Loss: 1908.6840 &lt;br /&gt;
Batch 140/157 - Loss: 2345.2627 &lt;br /&gt;
Batch 157/157 - Loss: 1830.1548 &lt;br /&gt;
Cosine phase: learning rate set to 0.000002 &lt;br /&gt;
Epoch 100 completed in 0:00:06.242254 &lt;br /&gt;
Train Loss: 2037.4231 &lt;br /&gt;
Val Loss: 1928.0867 &lt;br /&gt;
Final model saved to ssd_pascal_voc_final.pth &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/ssd/ssd-loss-plot-new.png&quot; alt=&quot;&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;In the next few weeks, my goal is to review all the code to deepen my understanding and ensure everything is well-optimized. I also plan to upload the model weights to Hugging Face and begin working on inference code to test the model‚Äôs potential. Once I‚Äôve evaluated its strengths and weaknesses, I‚Äôll focus on refining the model and retraining it to achieve even better results.&lt;/p&gt;

&lt;p&gt;This post documents the state of the SSD model as of April 6, 2025.&lt;br /&gt;
To see the current state of the model visit:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/adrirubio/ml-rover/blob/main/ssd/ssd-object-detection.py&quot;&gt;SSD object detection model&lt;/a&gt;&lt;/p&gt;
</description><description>&lt;p class=&quot;intro&quot;&gt;&lt;span class=&quot;dropcap&quot;&gt;H&lt;/span&gt;ello and welcome! This week, I completed the model and began the debugging process, which involved making numerous changes across the entire system. After that, I kicked off the first full training run, made some adjustments based on the results, and retrained the model. So far, the results are looking very promising!&lt;/p&gt;
</description><pubDate>Sun, 06 Apr 2025 00:00:00 +0200</pubDate>
        <link>http://localhost:4000/blog/finishing-model-and-training/</link>
        <guid isPermaLink="true">http://localhost:4000/blog/finishing-model-and-training/</guid></item></channel>
</rss>
